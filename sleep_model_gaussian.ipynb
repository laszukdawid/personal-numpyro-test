{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "017a8a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "from jax import vmap\n",
    "import jax.numpy as jnp\n",
    "import jax.random as random\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import (\n",
    "    MCMC,\n",
    "    NUTS,\n",
    "    init_to_feasible,\n",
    "    init_to_median,\n",
    "    init_to_sample,\n",
    "    init_to_uniform,\n",
    "    init_to_value,\n",
    ")\n",
    "\n",
    "matplotlib.use(\"Agg\")  # noqa: E402\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92dfd967",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# squared exponential kernel with diagonal noise term\n",
    "def kernel(X, Z, var, length, noise, jitter=1.0e-6, include_noise=True):\n",
    "    deltaXsq = jnp.power((X[:, None] - Z) / length, 2.0)\n",
    "    k = var * jnp.exp(-0.5 * deltaXsq)\n",
    "    if include_noise:\n",
    "        k += (noise + jitter) * jnp.eye(X.shape[0])\n",
    "    return k\n",
    "\n",
    "\n",
    "def model(X, Y):\n",
    "    # set uninformative log-normal priors on our three kernel hyperparameters\n",
    "    var = numpyro.sample(\"kernel_var\", dist.LogNormal(0.0, 10.0))\n",
    "    noise = numpyro.sample(\"kernel_noise\", dist.LogNormal(0.0, 10.0))\n",
    "    length = numpyro.sample(\"kernel_length\", dist.LogNormal(0.0, 10.0))\n",
    "\n",
    "    # compute kernel\n",
    "    k = kernel(X, X, var, length, noise)\n",
    "\n",
    "    # sample Y according to the standard gaussian process formula\n",
    "    numpyro.sample(\n",
    "        \"Y\",\n",
    "        dist.MultivariateNormal(loc=jnp.zeros(X.shape[0]), covariance_matrix=k),\n",
    "        obs=Y,\n",
    "    )\n",
    "\n",
    "\n",
    "# helper function for doing hmc inference\n",
    "def run_inference(model, args, rng_key, X, Y):\n",
    "    start = time.time()\n",
    "    # demonstrate how to use different HMC initialization strategies\n",
    "    if args.init_strategy == \"value\":\n",
    "        init_strategy = init_to_value(\n",
    "            values={\"kernel_var\": 1.0, \"kernel_noise\": 0.05, \"kernel_length\": 0.5}\n",
    "        )\n",
    "    elif args.init_strategy == \"median\":\n",
    "        init_strategy = init_to_median(num_samples=10)\n",
    "    elif args.init_strategy == \"feasible\":\n",
    "        init_strategy = init_to_feasible()\n",
    "    elif args.init_strategy == \"sample\":\n",
    "        init_strategy = init_to_sample()\n",
    "    elif args.init_strategy == \"uniform\":\n",
    "        init_strategy = init_to_uniform(radius=1)\n",
    "    kernel = NUTS(model, init_strategy=init_strategy)\n",
    "    mcmc = MCMC(\n",
    "        kernel,\n",
    "        num_warmup=args.num_warmup,\n",
    "        num_samples=args.num_samples,\n",
    "        num_chains=args.num_chains,\n",
    "        thinning=args.thinning,\n",
    "        progress_bar=False if \"NUMPYRO_SPHINXBUILD\" in os.environ else True,\n",
    "    )\n",
    "    mcmc.run(rng_key, X, Y)\n",
    "    mcmc.print_summary()\n",
    "    print(\"\\nMCMC elapsed time:\", time.time() - start)\n",
    "    return mcmc.get_samples()\n",
    "\n",
    "\n",
    "# do GP prediction for a given set of hyperparameters. this makes use of the well-known\n",
    "# formula for gaussian process predictions\n",
    "def predict(rng_key, X, Y, X_test, var, length, noise):\n",
    "    # compute kernels between train and test data, etc.\n",
    "    k_pp = kernel(X_test, X_test, var, length, noise, include_noise=True)\n",
    "    k_pX = kernel(X_test, X, var, length, noise, include_noise=False)\n",
    "    k_XX = kernel(X, X, var, length, noise, include_noise=True)\n",
    "    K_xx_inv = jnp.linalg.inv(k_XX)\n",
    "    K = k_pp - jnp.matmul(k_pX, jnp.matmul(K_xx_inv, jnp.transpose(k_pX)))\n",
    "    sigma_noise = jnp.sqrt(jnp.clip(jnp.diag(K), a_min=0.0)) * jax.random.normal(\n",
    "        rng_key, X_test.shape[:1]\n",
    "    )\n",
    "    mean = jnp.matmul(k_pX, jnp.matmul(K_xx_inv, Y))\n",
    "    # we return both the mean function and a sample from the posterior predictive for the\n",
    "    # given set of hyperparameters\n",
    "    return mean, mean + sigma_noise\n",
    "\n",
    "\n",
    "# create artificial regression dataset\n",
    "def get_data(N=30, sigma_obs=0.15, N_test=400):\n",
    "    np.random.seed(0)\n",
    "    X = jnp.linspace(-1, 1, N)\n",
    "    Y = X + 0.2 * jnp.power(X, 3.0) + 0.5 * jnp.power(0.5 + X, 2.0) * jnp.sin(4.0 * X)\n",
    "    Y += sigma_obs * np.random.randn(N)\n",
    "    Y -= jnp.mean(Y)\n",
    "    Y /= jnp.std(Y)\n",
    "\n",
    "    assert X.shape == (N,)\n",
    "    assert Y.shape == (N,)\n",
    "\n",
    "    X_test = jnp.linspace(-1.3, 1.3, N_test)\n",
    "\n",
    "    return X, Y, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1509112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultArgs:\n",
    "    \n",
    "    num_samples = 1000\n",
    "    num_warmup = 1000\n",
    "    num_chains = 1\n",
    "    thinning = 2\n",
    "    num_data = 25\n",
    "    device = \"cpu\"  # choices = [\"cpu\", \"gpu\"]\n",
    "    init_strategy = \"median\" # choices=[\"median\", \"feasible\", \"value\", \"uniform\", \"sample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7fc3217",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(args):\n",
    "    X, Y, X_test = get_data(N=args.num_data)\n",
    "\n",
    "    # do inference\n",
    "    rng_key, rng_key_predict = random.split(random.PRNGKey(0))\n",
    "    samples = run_inference(model, args, rng_key, X, Y)\n",
    "\n",
    "    # do prediction\n",
    "    vmap_args = (\n",
    "        random.split(rng_key_predict, samples[\"kernel_var\"].shape[0]),\n",
    "        samples[\"kernel_var\"],\n",
    "        samples[\"kernel_length\"],\n",
    "        samples[\"kernel_noise\"],\n",
    "    )\n",
    "    means, predictions = vmap(\n",
    "        lambda rng_key, var, length, noise: predict(\n",
    "            rng_key, X, Y, X_test, var, length, noise\n",
    "        )\n",
    "    )(*vmap_args)\n",
    "\n",
    "    mean_prediction = np.mean(means, axis=0)\n",
    "    percentiles = np.percentile(predictions, [5.0, 95.0], axis=0)\n",
    "\n",
    "    # make plots\n",
    "    fig, ax = plt.subplots(figsize=(8, 6), constrained_layout=True)\n",
    "\n",
    "    # plot training data\n",
    "    ax.plot(X, Y, \"kx\")\n",
    "    # plot 90% confidence level of predictions\n",
    "    ax.fill_between(X_test, percentiles[0, :], percentiles[1, :], color=\"lightblue\")\n",
    "    # plot mean prediction\n",
    "    ax.plot(X_test, mean_prediction, \"blue\", ls=\"solid\", lw=2.0)\n",
    "    ax.set(xlabel=\"X\", ylabel=\"Y\", title=\"Mean predictions with 90% CI\")\n",
    "\n",
    "    plt.savefig(\"gp_plot.pdf\")\n",
    "\n",
    "\n",
    "#     parser = argparse.ArgumentParser(description=\"Gaussian Process example\")\n",
    "#     parser.add_argument(\"-n\", \"--num-samples\", nargs=\"?\", default=1000, type=int)\n",
    "#     parser.add_argument(\"--num-warmup\", nargs=\"?\", default=1000, type=int)\n",
    "#     parser.add_argument(\"--num-chains\", nargs=\"?\", default=1, type=int)\n",
    "#     parser.add_argument(\"--thinning\", nargs=\"?\", default=2, type=int)\n",
    "#     parser.add_argument(\"--num-data\", nargs=\"?\", default=25, type=int)\n",
    "#     parser.add_argument(\"--device\", default=\"cpu\", type=str, help='use \"cpu\" or \"gpu\".')\n",
    "#     parser.add_argument(\n",
    "#         \"--init-strategy\",\n",
    "#         default=\"median\",\n",
    "#         type=str,\n",
    "#         choices=[\"median\", \"feasible\", \"value\", \"uniform\", \"sample\"],\n",
    "#     )\n",
    "#     args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc7f006d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|â–ˆ| 2000/2000 [00:02<00:00, 866.22it/s, 5 steps of size 4.60e-01. ac\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "  kernel_length      0.69      0.25      0.66      0.33      1.02    423.11      1.00\n",
      "   kernel_noise      0.06      0.02      0.06      0.03      0.09    433.78      1.00\n",
      "     kernel_var      3.77     10.99      1.34      0.20      7.39    402.84      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "\n",
      "MCMC elapsed time: 4.166219472885132\n"
     ]
    }
   ],
   "source": [
    "args = DefaultArgs()    \n",
    "\n",
    "numpyro.set_platform(args.device)\n",
    "numpyro.set_host_device_count(args.num_chains)\n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f8c874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
